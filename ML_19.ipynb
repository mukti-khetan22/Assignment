{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab33344",
   "metadata": {},
   "source": [
    "\n",
    "1. a) For the first set of centroids (15, 32), the clusters are: (5, 10, 15, 20) and (25, 30, 35). For the second set of centroids (12, 30), the clusters are: (5, 10, 15) and (20, 25, 30, 35). b) For the first set of centroids, SSE = 125. For the second set of centroids, SSE = 75.\n",
    "2.\tMarket Basket Research uses association analysis concepts to identify which items are frequently bought together by customers, and to find relationships between products based on their purchase history.\n",
    "3.\tAn example of the Apriori algorithm for learning association rules is as follows: Given a set of transactions {A, B, C, D, E}, with a minimum support count of 2, the algorithm would first identify frequent itemsets {A, B}, {A, C}, {A, D}, {B, C}, {B, D}, {C, D}, each with a count of at least 2. Then, it would generate association rules from these itemsets, such as {A, B} => {C} or {B, C} => {D}.\n",
    "4.\tThe distance between clusters in hierarchical clustering is typically measured using one of several metrics, such as Euclidean distance or Manhattan distance. The metric is used to calculate the distance between each pair of clusters, and the two closest clusters are merged at each iteration until a stopping criterion is met.\n",
    "5.\tTo recompute the cluster centroids in the k-means algorithm, the mean of each cluster's data points is calculated, and these means are used as the new centroid locations for each cluster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e334eb",
   "metadata": {},
   "source": [
    "6.\tQ: At the start of the clustering exercise, discuss one method for determining the required number of clusters. A: One method for determining the required number of clusters is the elbow method, which involves plotting the SSE (sum of squared errors) against the number of clusters and selecting the number of clusters at the \"elbow\" or point of diminishing returns.\n",
    "7.\tQ: Discuss the k-means algorithm's advantages and disadvantages. A: Advantages of the k-means algorithm include its simplicity and efficiency, but its disadvantages include its sensitivity to initial conditions and the need to specify the number of clusters.\n",
    "8.\tQ: Draw a diagram to demonstrate the principle of clustering. A: Hierarchical cluster analysis begins by separating each object into a cluster by itself. At each stage of the analysis, the criterion by which objects are separated is relaxed in order to link the two most similar clusters until all of the objects are joined in a complete classification tree. \n",
    "9.\tQ: What would the cluster centroids be if you were to run a second iteration? What would this clustering's SSE be? A: It is not possible to determine the cluster centroids or SSE without knowing the results of the first iteration of the k-means algorithm.\n",
    "10.\tQ: In a software project, the team is attempting to determine if software flaws discovered during testing are identical. Can you explain this process using a simple diagram assuming you have 20 defect data points clustered into 5 clusters using the k-means algorithm? A: However, the process involves identifying common characteristics among the defects, clustering them into 5 groups based on these characteristics, and labeling any new defect based on its similarity to the pre-identified clusters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a76f197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
