{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d1ba77d",
   "metadata": {},
   "source": [
    "1.\tAn independent variable is the variable that is changed or controlled in a scientific experiment, while a dependent variable is the variable being tested and measured in a scientific experiment.\n",
    "2.\tSimple linear regression is a statistical method that allows us to study the relationship between two continuous variables, where one variable predicts the other using a straight line. For example, studying the relationship between the number of hours a student studies and their exam score.\n",
    "3.\tIn linear regression, the slope is the coefficient that represents the rate at which the dependent variable changes as the independent variable changes.\n",
    "4.\tThe graph's slope would be undefined since the two points have the same y-coordinate.\n",
    "5.\tIn linear regression, the conditions for a positive slope are that as the independent variable increases, the dependent variable also increases.\n",
    "6.\tIn linear regression, the conditions for a negative slope are that as the independent variable increases, the dependent variable decreases.\n",
    "7.\tMultiple linear regression is a statistical method that examines the linear relationship between two or more independent variables and a dependent variable.\n",
    "8.\tIn multiple linear regression, the number of squares due to error measures the difference between the actual value and the predicted value of the dependent variable.\n",
    "9.\tIn multiple linear regression, the number of squares due to regression measures how much of the variance in the dependent variable is explained by the independent variables.\n",
    "10.\tIn a regression equation, multicollinearity occurs when two or more independent variables in the model are highly correlated, making it difficult to identify the individual effect of each variable on the dependent variable.\n",
    "11.\tHeteroskedasticity is a condition in which the variance of the errors in a regression model is not constant across all levels of the independent variable, indicating that the error terms are not uniformly distributed.\n",
    "12.\tRidge regression is a type of linear regression that adds a penalty term to the least squares equation to reduce the impact of multicollinearity in the model.\n",
    "13.\tLasso regression is a type of linear regression that adds a penalty term to the least squares equation to perform variable selection by shrinking some of the regression coefficients to zero.\n",
    "14.\tPolynomial regression is a statistical method that models the relationship between a dependent variable and an independent variable by fitting a polynomial equation of degree n to the data.\n",
    "15.\tA basis function is a mathematical function that is used to represent a complex relationship between the dependent variable and independent variable(s) by transforming the original input into a new feature space.\n",
    "16.\tLogistic regression is a statistical method used to analyze the relationship between a dependent variable and one or more independent variables when the dependent variable is binary. The method models the log odds of the dependent variable being in one category versus the other as a linear function of the independent variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065dd2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
